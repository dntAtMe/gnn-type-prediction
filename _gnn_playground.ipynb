{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:34:55.587536700Z",
     "start_time": "2024-01-08T01:34:51.490026900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1613,  0.6986],\n",
      "        [ 0.0789,  0.7622],\n",
      "        [-0.1312,  0.6711],\n",
      "        [-0.0755,  0.7066],\n",
      "        [-0.2191,  0.6435],\n",
      "        [-0.2056,  0.6470],\n",
      "        [-0.2087,  0.6525]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class GatedGNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(GatedGNNLayer, self).__init__(aggr='add')\n",
    "        self.message_nn = nn.Linear(out_channels, out_channels)\n",
    "        self.update_nn = nn.GRUCell(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, h):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        return self.propagate(edge_index, x=x, h=h)\n",
    "\n",
    "    def message(self, h_j, x_i):\n",
    "        return self.message_nn(h_j)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        return self.update_nn(aggr_out, h)\n",
    "\n",
    "class GGNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_steps):\n",
    "        super(GGNN, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.ggnn_layer = GatedGNNLayer(in_channels, out_channels)\n",
    "        self.h_init = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.h_init(x)\n",
    "        for _ in range(self.n_steps):\n",
    "            h = self.ggnn_layer(x, edge_index, h)\n",
    "        return h\n",
    "\n",
    "num_features = 10\n",
    "num_classes = 2\n",
    "num_nodes = 7\n",
    "n_steps = 3\n",
    "\n",
    "x = torch.randn(num_nodes, num_features)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 0], [1, 0, 3, 2, 5, 4, 0, 6]])\n",
    "\n",
    "model = GGNN(num_features, num_classes, n_steps)\n",
    "output = model(x, edge_index)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[10, 1], edge_index=[2, 45], y=[10])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GGNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_steps):\n",
    "        super(GGNN, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.ggnn_layer = GatedGNNLayer(in_channels, out_channels)\n",
    "        self.h_init = nn.Linear(in_channels, out_channels)\n",
    "        self.classifier = nn.Linear(out_channels, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.h_init(x)  # Initialize hidden state\n",
    "        for _ in range(self.n_steps):\n",
    "            h = self.ggnn_layer(x, edge_index, h)\n",
    "        return torch.softmax(self.classifier(h), dim=1)\n",
    "\n",
    "node_features = torch.arange(1, 11).view(-1, 1).float()\n",
    "node_labels = torch.tensor([1]*5 + [0]*5)\n",
    "\n",
    "# Fully connected graph\n",
    "edge_index = torch.combinations(torch.arange(10), r=2).t().contiguous()\n",
    "\n",
    "# Graph Data\n",
    "data = Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:13.077492700Z",
     "start_time": "2024-01-08T01:35:13.033495600Z"
    }
   },
   "id": "6cfe30a2d7cd0c50",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7505108118057251\n",
      "Epoch 1, Loss: 0.7345073223114014\n",
      "Epoch 2, Loss: 0.7209871411323547\n",
      "Epoch 3, Loss: 0.710412323474884\n",
      "Epoch 4, Loss: 0.7028274536132812\n",
      "Epoch 5, Loss: 0.6978403329849243\n",
      "Epoch 6, Loss: 0.6947283744812012\n",
      "Epoch 7, Loss: 0.6926599740982056\n",
      "Epoch 8, Loss: 0.6908921003341675\n",
      "Epoch 9, Loss: 0.6888076066970825\n",
      "Epoch 10, Loss: 0.6857887506484985\n",
      "Epoch 11, Loss: 0.681104838848114\n",
      "Epoch 12, Loss: 0.6741296052932739\n",
      "Epoch 13, Loss: 0.6648052930831909\n",
      "Epoch 14, Loss: 0.6538203954696655\n",
      "Epoch 15, Loss: 0.6421905755996704\n",
      "Epoch 16, Loss: 0.6306681632995605\n",
      "Epoch 17, Loss: 0.6196225881576538\n",
      "Epoch 18, Loss: 0.6091436147689819\n",
      "Epoch 19, Loss: 0.5991804003715515\n",
      "Epoch 20, Loss: 0.5896567702293396\n",
      "Epoch 21, Loss: 0.5805214643478394\n",
      "Epoch 22, Loss: 0.5717483162879944\n",
      "Epoch 23, Loss: 0.5633229613304138\n",
      "Epoch 24, Loss: 0.5552337169647217\n",
      "Epoch 25, Loss: 0.5474665760993958\n",
      "Epoch 26, Loss: 0.5400010347366333\n",
      "Epoch 27, Loss: 0.5328039526939392\n",
      "Epoch 28, Loss: 0.5258253812789917\n",
      "Epoch 29, Loss: 0.5189982652664185\n",
      "Epoch 30, Loss: 0.5122431516647339\n",
      "Epoch 31, Loss: 0.5054768323898315\n",
      "Epoch 32, Loss: 0.49862250685691833\n",
      "Epoch 33, Loss: 0.4916210174560547\n",
      "Epoch 34, Loss: 0.48444366455078125\n",
      "Epoch 35, Loss: 0.47710591554641724\n",
      "Epoch 36, Loss: 0.46968260407447815\n",
      "Epoch 37, Loss: 0.46231985092163086\n",
      "Epoch 38, Loss: 0.4552331864833832\n",
      "Epoch 39, Loss: 0.44867509603500366\n",
      "Epoch 40, Loss: 0.4428509771823883\n",
      "Epoch 41, Loss: 0.4377923905849457\n",
      "Epoch 42, Loss: 0.43325918912887573\n",
      "Epoch 43, Loss: 0.4287997782230377\n",
      "Epoch 44, Loss: 0.4240015149116516\n",
      "Epoch 45, Loss: 0.418753445148468\n",
      "Epoch 46, Loss: 0.41330963373184204\n",
      "Epoch 47, Loss: 0.40813177824020386\n",
      "Epoch 48, Loss: 0.40361157059669495\n",
      "Epoch 49, Loss: 0.39982515573501587\n",
      "Epoch 50, Loss: 0.39648956060409546\n",
      "Epoch 51, Loss: 0.3931702673435211\n",
      "Epoch 52, Loss: 0.38956865668296814\n",
      "Epoch 53, Loss: 0.38569027185440063\n",
      "Epoch 54, Loss: 0.3818221688270569\n",
      "Epoch 55, Loss: 0.3783317804336548\n",
      "Epoch 56, Loss: 0.3753740191459656\n",
      "Epoch 57, Loss: 0.37273329496383667\n",
      "Epoch 58, Loss: 0.3700195252895355\n",
      "Epoch 59, Loss: 0.3670751452445984\n",
      "Epoch 60, Loss: 0.3641299605369568\n",
      "Epoch 61, Loss: 0.36152371764183044\n",
      "Epoch 62, Loss: 0.35935038328170776\n",
      "Epoch 63, Loss: 0.35741645097732544\n",
      "Epoch 64, Loss: 0.35548412799835205\n",
      "Epoch 65, Loss: 0.35349634289741516\n",
      "Epoch 66, Loss: 0.3515821695327759\n",
      "Epoch 67, Loss: 0.34988489747047424\n",
      "Epoch 68, Loss: 0.34840378165245056\n",
      "Epoch 69, Loss: 0.34700629115104675\n",
      "Epoch 70, Loss: 0.3455907702445984\n",
      "Epoch 71, Loss: 0.34419724345207214\n",
      "Epoch 72, Loss: 0.3429323732852936\n",
      "Epoch 73, Loss: 0.3418336808681488\n",
      "Epoch 74, Loss: 0.3408398926258087\n",
      "Epoch 75, Loss: 0.3398676812648773\n",
      "Epoch 76, Loss: 0.33889415860176086\n",
      "Epoch 77, Loss: 0.33796292543411255\n",
      "Epoch 78, Loss: 0.33712300658226013\n",
      "Epoch 79, Loss: 0.3363717794418335\n",
      "Epoch 80, Loss: 0.3356611728668213\n",
      "Epoch 81, Loss: 0.33495426177978516\n",
      "Epoch 82, Loss: 0.3342617154121399\n",
      "Epoch 83, Loss: 0.33361631631851196\n",
      "Epoch 84, Loss: 0.33302921056747437\n",
      "Epoch 85, Loss: 0.3324816823005676\n",
      "Epoch 86, Loss: 0.33195045590400696\n",
      "Epoch 87, Loss: 0.33143001794815063\n",
      "Epoch 88, Loss: 0.3309321999549866\n",
      "Epoch 89, Loss: 0.33046889305114746\n",
      "Epoch 90, Loss: 0.3300391137599945\n",
      "Epoch 91, Loss: 0.32963094115257263\n",
      "Epoch 92, Loss: 0.32923394441604614\n",
      "Epoch 93, Loss: 0.3288474380970001\n",
      "Epoch 94, Loss: 0.3284775912761688\n",
      "Epoch 95, Loss: 0.3281289339065552\n",
      "Epoch 96, Loss: 0.32779961824417114\n",
      "Epoch 97, Loss: 0.3274838328361511\n",
      "Epoch 98, Loss: 0.3271772861480713\n",
      "Epoch 99, Loss: 0.32687944173812866\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:14.825791300Z",
     "start_time": "2024-01-08T01:35:14.457793200Z"
    }
   },
   "id": "1424c172f910d6f3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    predicted_labels = pred.max(1)[1]\n",
    "    print(predicted_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:24.579709800Z",
     "start_time": "2024-01-08T01:35:24.534701Z"
    }
   },
   "id": "97dff940fb6b4137",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[10, 1], edge_index=[2, 45], y=[10], train_mask=[10])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "node_features = torch.arange(1, 11).view(-1, 1).float()\n",
    "node_labels = torch.tensor([1]*5 + [0]*5)\n",
    "\n",
    "mask = torch.randperm(10)[:3]\n",
    "train_mask = torch.ones(10, dtype=torch.bool)\n",
    "train_mask[mask] = False\n",
    "\n",
    "edge_index = torch.combinations(torch.arange(10), r=2).t().contiguous()\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index, y=node_labels, train_mask=train_mask)\n",
    "data.validate(raise_on_error=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:26.093978100Z",
     "start_time": "2024-01-08T01:35:26.027977200Z"
    }
   },
   "id": "ab948462d9ca28e5",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7045034766197205\n",
      "Epoch 1, Loss: 0.6975182890892029\n",
      "Epoch 2, Loss: 0.6906991004943848\n",
      "Epoch 3, Loss: 0.6840797066688538\n",
      "Epoch 4, Loss: 0.6778831481933594\n",
      "Epoch 5, Loss: 0.6722598075866699\n",
      "Epoch 6, Loss: 0.667226254940033\n",
      "Epoch 7, Loss: 0.6626810431480408\n",
      "Epoch 8, Loss: 0.6584886908531189\n",
      "Epoch 9, Loss: 0.6545923948287964\n",
      "Epoch 10, Loss: 0.6509963870048523\n",
      "Epoch 11, Loss: 0.6472967863082886\n",
      "Epoch 12, Loss: 0.6428599953651428\n",
      "Epoch 13, Loss: 0.6377127766609192\n",
      "Epoch 14, Loss: 0.6321994066238403\n",
      "Epoch 15, Loss: 0.6263987421989441\n",
      "Epoch 16, Loss: 0.6200027465820312\n",
      "Epoch 17, Loss: 0.6127097010612488\n",
      "Epoch 18, Loss: 0.6045129895210266\n",
      "Epoch 19, Loss: 0.5957077741622925\n",
      "Epoch 20, Loss: 0.5865606069564819\n",
      "Epoch 21, Loss: 0.5766382813453674\n",
      "Epoch 22, Loss: 0.5658078789710999\n",
      "Epoch 23, Loss: 0.5547047257423401\n",
      "Epoch 24, Loss: 0.5432830452919006\n",
      "Epoch 25, Loss: 0.5311815142631531\n",
      "Epoch 26, Loss: 0.5188978910446167\n",
      "Epoch 27, Loss: 0.506672739982605\n",
      "Epoch 28, Loss: 0.49388226866722107\n",
      "Epoch 29, Loss: 0.4812966287136078\n",
      "Epoch 30, Loss: 0.46874117851257324\n",
      "Epoch 31, Loss: 0.4561760723590851\n",
      "Epoch 32, Loss: 0.4444293975830078\n",
      "Epoch 33, Loss: 0.4328436553478241\n",
      "Epoch 34, Loss: 0.42226552963256836\n",
      "Epoch 35, Loss: 0.4119042456150055\n",
      "Epoch 36, Loss: 0.40254881978034973\n",
      "Epoch 37, Loss: 0.3934907913208008\n",
      "Epoch 38, Loss: 0.38544052839279175\n",
      "Epoch 39, Loss: 0.3778577148914337\n",
      "Epoch 40, Loss: 0.37125569581985474\n",
      "Epoch 41, Loss: 0.36513641476631165\n",
      "Epoch 42, Loss: 0.35983362793922424\n",
      "Epoch 43, Loss: 0.35492515563964844\n",
      "Epoch 44, Loss: 0.350674569606781\n",
      "Epoch 45, Loss: 0.3467739224433899\n",
      "Epoch 46, Loss: 0.3434261977672577\n",
      "Epoch 47, Loss: 0.3404240012168884\n",
      "Epoch 48, Loss: 0.3378100097179413\n",
      "Epoch 49, Loss: 0.33552056550979614\n",
      "Epoch 50, Loss: 0.33346161246299744\n",
      "Epoch 51, Loss: 0.33168715238571167\n",
      "Epoch 52, Loss: 0.33007678389549255\n",
      "Epoch 53, Loss: 0.3286650478839874\n",
      "Epoch 54, Loss: 0.32742902636528015\n",
      "Epoch 55, Loss: 0.32631179690361023\n",
      "Epoch 56, Loss: 0.3253364861011505\n",
      "Epoch 57, Loss: 0.3244767189025879\n",
      "Epoch 58, Loss: 0.3237006366252899\n",
      "Epoch 59, Loss: 0.32300958037376404\n",
      "Epoch 60, Loss: 0.3223974108695984\n",
      "Epoch 61, Loss: 0.32184353470802307\n",
      "Epoch 62, Loss: 0.32133981585502625\n",
      "Epoch 63, Loss: 0.320887953042984\n",
      "Epoch 64, Loss: 0.3204822838306427\n",
      "Epoch 65, Loss: 0.3201132118701935\n",
      "Epoch 66, Loss: 0.31977608799934387\n",
      "Epoch 67, Loss: 0.31947061419487\n",
      "Epoch 68, Loss: 0.3191942274570465\n",
      "Epoch 69, Loss: 0.3189413845539093\n",
      "Epoch 70, Loss: 0.3187079131603241\n",
      "Epoch 71, Loss: 0.3184930384159088\n",
      "Epoch 72, Loss: 0.3182961642742157\n",
      "Epoch 73, Loss: 0.3181147277355194\n",
      "Epoch 74, Loss: 0.3179461359977722\n",
      "Epoch 75, Loss: 0.3177889287471771\n",
      "Epoch 76, Loss: 0.31764283776283264\n",
      "Epoch 77, Loss: 0.317507266998291\n",
      "Epoch 78, Loss: 0.3173809349536896\n",
      "Epoch 79, Loss: 0.31726256012916565\n",
      "Epoch 80, Loss: 0.3171512186527252\n",
      "Epoch 81, Loss: 0.31704673171043396\n",
      "Epoch 82, Loss: 0.31694868206977844\n",
      "Epoch 83, Loss: 0.3168565332889557\n",
      "Epoch 84, Loss: 0.31676942110061646\n",
      "Epoch 85, Loss: 0.3166868984699249\n",
      "Epoch 86, Loss: 0.31660860776901245\n",
      "Epoch 87, Loss: 0.31653428077697754\n",
      "Epoch 88, Loss: 0.3164637088775635\n",
      "Epoch 89, Loss: 0.3163965344429016\n",
      "Epoch 90, Loss: 0.31633248925209045\n",
      "Epoch 91, Loss: 0.3162711560726166\n",
      "Epoch 92, Loss: 0.3162124454975128\n",
      "Epoch 93, Loss: 0.3161562979221344\n",
      "Epoch 94, Loss: 0.31610244512557983\n",
      "Epoch 95, Loss: 0.31605076789855957\n",
      "Epoch 96, Loss: 0.31600111722946167\n",
      "Epoch 97, Loss: 0.31595325469970703\n",
      "Epoch 98, Loss: 0.31590721011161804\n",
      "Epoch 99, Loss: 0.3158627450466156\n"
     ]
    }
   ],
   "source": [
    "model = GGNN(1, num_classes, n_steps)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:27.885785700Z",
     "start_time": "2024-01-08T01:35:27.501787Z"
    }
   },
   "id": "86f38b2de3a5cd53",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for unknown nodes: tensor([1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    predicted_labels = pred.max(1)[1]\n",
    "\n",
    "    predictions_for_unknown = predicted_labels[~data.train_mask]\n",
    "    print(\"Predictions for unknown nodes:\", predictions_for_unknown)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:30.601577200Z",
     "start_time": "2024-01-08T01:35:30.554576800Z"
    }
   },
   "id": "3fbdbcb99ee66e4d",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[50, 1], edge_index=[2, 1275], y=[50])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def create_graph(node_values):\n",
    "    num_nodes = len(node_values)\n",
    "    node_features = torch.tensor(node_values, dtype=torch.float).view(-1, 1)\n",
    "    node_labels = torch.tensor([1 if value < 50 else 0 for value in node_values], dtype=torch.long)\n",
    "\n",
    "    edge_index = torch.tensor(np.random.choice(num_nodes, (2, num_nodes * 2)), dtype=torch.long)\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
    "\n",
    "def create_graph_v2(node_values):\n",
    "    num_nodes = len(node_values)\n",
    "    node_features = torch.tensor(node_values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "\n",
    "    edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if node_values[i] >= node_values[j]], dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    node_labels = torch.tensor([1 if len(np.where(edge_index[0] == i)[0]) > 25 else 0 for i in range(num_nodes)], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
    "\n",
    "train_values = np.random.choice(range(1, 100), 50, replace=False)\n",
    "test_values = np.random.choice(range(1, 100), 50, replace=False)\n",
    "\n",
    "train_data = create_graph_v2(train_values)\n",
    "test_data = create_graph_v2(test_values)\n",
    "\n",
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:32.139113700Z",
     "start_time": "2024-01-08T01:35:32.103151300Z"
    }
   },
   "id": "bad5112d87390030",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Features: tensor([[42.],\n",
      "        [45.],\n",
      "        [98.],\n",
      "        [10.],\n",
      "        [19.]])\n",
      "Training Data - Labels: tensor([0, 0, 1, 0, 0])\n",
      "Testing Data - Features: tensor([[76.],\n",
      "        [16.],\n",
      "        [39.],\n",
      "        [56.],\n",
      "        [54.]])\n",
      "Testing Data - Labels: tensor([1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data - Features:\", train_data.x[:5])\n",
    "print(\"Training Data - Labels:\", train_data.y[:5])\n",
    "print(\"Testing Data - Features:\", test_data.x[:5])\n",
    "print(\"Testing Data - Labels:\", test_data.y[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:35.316842400Z",
     "start_time": "2024-01-08T01:35:35.268841700Z"
    }
   },
   "id": "eb93ba92189da0d8",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6945098042488098\n",
      "Epoch 1, Loss: 0.6083464026451111\n",
      "Epoch 2, Loss: 0.7125699520111084\n",
      "Epoch 3, Loss: 0.6801719665527344\n",
      "Epoch 4, Loss: 0.5837964415550232\n",
      "Epoch 5, Loss: 0.573807954788208\n",
      "Epoch 6, Loss: 0.6017743349075317\n",
      "Epoch 7, Loss: 0.602378785610199\n",
      "Epoch 8, Loss: 0.60025954246521\n",
      "Epoch 9, Loss: 0.5961257815361023\n",
      "Epoch 10, Loss: 0.5903216600418091\n",
      "Epoch 11, Loss: 0.5836807489395142\n",
      "Epoch 12, Loss: 0.5762725472450256\n",
      "Epoch 13, Loss: 0.5689895153045654\n",
      "Epoch 14, Loss: 0.5619006156921387\n",
      "Epoch 15, Loss: 0.555547297000885\n",
      "Epoch 16, Loss: 0.5503217577934265\n",
      "Epoch 17, Loss: 0.5465654134750366\n",
      "Epoch 18, Loss: 0.5443823337554932\n",
      "Epoch 19, Loss: 0.5428814888000488\n",
      "Epoch 20, Loss: 0.5416820645332336\n",
      "Epoch 21, Loss: 0.5403760671615601\n",
      "Epoch 22, Loss: 0.5385956764221191\n",
      "Epoch 23, Loss: 0.5361430644989014\n",
      "Epoch 24, Loss: 0.5330132842063904\n",
      "Epoch 25, Loss: 0.5293608903884888\n",
      "Epoch 26, Loss: 0.5254391431808472\n",
      "Epoch 27, Loss: 0.5215299129486084\n",
      "Epoch 28, Loss: 0.5178781747817993\n",
      "Epoch 29, Loss: 0.5146434307098389\n",
      "Epoch 30, Loss: 0.5118764638900757\n",
      "Epoch 31, Loss: 0.5095259547233582\n",
      "Epoch 32, Loss: 0.5074677467346191\n",
      "Epoch 33, Loss: 0.5055474638938904\n",
      "Epoch 34, Loss: 0.5036208033561707\n",
      "Epoch 35, Loss: 0.501584529876709\n",
      "Epoch 36, Loss: 0.49939119815826416\n",
      "Epoch 37, Loss: 0.49704957008361816\n",
      "Epoch 38, Loss: 0.4946136176586151\n",
      "Epoch 39, Loss: 0.4921644628047943\n",
      "Epoch 40, Loss: 0.48978832364082336\n",
      "Epoch 41, Loss: 0.4875553846359253\n",
      "Epoch 42, Loss: 0.4855025112628937\n",
      "Epoch 43, Loss: 0.4836254417896271\n",
      "Epoch 44, Loss: 0.4818822145462036\n",
      "Epoch 45, Loss: 0.4802078902721405\n",
      "Epoch 46, Loss: 0.478536456823349\n",
      "Epoch 47, Loss: 0.47682151198387146\n",
      "Epoch 48, Loss: 0.47504833340644836\n",
      "Epoch 49, Loss: 0.47323453426361084\n",
      "Epoch 50, Loss: 0.47141921520233154\n",
      "Epoch 51, Loss: 0.46964722871780396\n",
      "Epoch 52, Loss: 0.46795302629470825\n",
      "Epoch 53, Loss: 0.46635109186172485\n",
      "Epoch 54, Loss: 0.4648337662220001\n",
      "Epoch 55, Loss: 0.4633777141571045\n",
      "Epoch 56, Loss: 0.4619539976119995\n",
      "Epoch 57, Loss: 0.4605383574962616\n",
      "Epoch 58, Loss: 0.45911774039268494\n",
      "Epoch 59, Loss: 0.4576927125453949\n",
      "Epoch 60, Loss: 0.4562745690345764\n",
      "Epoch 61, Loss: 0.4548799991607666\n",
      "Epoch 62, Loss: 0.4535243511199951\n",
      "Epoch 63, Loss: 0.452216237783432\n",
      "Epoch 64, Loss: 0.45095497369766235\n",
      "Epoch 65, Loss: 0.4497320055961609\n",
      "Epoch 66, Loss: 0.44853460788726807\n",
      "Epoch 67, Loss: 0.4473513066768646\n",
      "Epoch 68, Loss: 0.44617587327957153\n",
      "Epoch 69, Loss: 0.4450087249279022\n",
      "Epoch 70, Loss: 0.4438555836677551\n",
      "Epoch 71, Loss: 0.4427241384983063\n",
      "Epoch 72, Loss: 0.4416203200817108\n",
      "Epoch 73, Loss: 0.4405461847782135\n",
      "Epoch 74, Loss: 0.43949949741363525\n",
      "Epoch 75, Loss: 0.43847522139549255\n",
      "Epoch 76, Loss: 0.4374677538871765\n",
      "Epoch 77, Loss: 0.4364730715751648\n",
      "Epoch 78, Loss: 0.4354900121688843\n",
      "Epoch 79, Loss: 0.4345199465751648\n",
      "Epoch 80, Loss: 0.4335656762123108\n",
      "Epoch 81, Loss: 0.4326300323009491\n",
      "Epoch 82, Loss: 0.43171432614326477\n",
      "Epoch 83, Loss: 0.43081796169281006\n",
      "Epoch 84, Loss: 0.4299388527870178\n",
      "Epoch 85, Loss: 0.4290742874145508\n",
      "Epoch 86, Loss: 0.4282221496105194\n",
      "Epoch 87, Loss: 0.4273817837238312\n",
      "Epoch 88, Loss: 0.4265534281730652\n",
      "Epoch 89, Loss: 0.42573824524879456\n",
      "Epoch 90, Loss: 0.42493736743927\n",
      "Epoch 91, Loss: 0.42415112257003784\n",
      "Epoch 92, Loss: 0.4233790338039398\n",
      "Epoch 93, Loss: 0.42262011766433716\n",
      "Epoch 94, Loss: 0.42187297344207764\n",
      "Epoch 95, Loss: 0.4211367070674896\n",
      "Epoch 96, Loss: 0.4204109311103821\n",
      "Epoch 97, Loss: 0.41969582438468933\n",
      "Epoch 98, Loss: 0.4189916253089905\n",
      "Epoch 99, Loss: 0.4182988405227661\n"
     ]
    }
   ],
   "source": [
    "model = GGNN(1, num_classes, n_steps)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data.x, train_data.edge_index)\n",
    "    loss = criterion(out, train_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:37.398273700Z",
     "start_time": "2024-01-08T01:35:37.005152100Z"
    }
   },
   "id": "db35d015a16d8e78",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_out = model(test_data.x, test_data.edge_index)\n",
    "    predicted_labels = test_out.max(1)[1]\n",
    "    accuracy = (predicted_labels == test_data.y).sum().item() / test_data.y.size(0)\n",
    "    print(\"Test Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T01:35:39.145367800Z",
     "start_time": "2024-01-08T01:35:39.120371400Z"
    }
   },
   "id": "347ab31632a9652e",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
